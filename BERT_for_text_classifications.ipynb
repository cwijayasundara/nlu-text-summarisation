{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT-for-text-classifications.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6THLBezsIhi"
      },
      "source": [
        "Make sure to select the GPU runtime (Menu > Runtime > Change Runtime Type) in Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0euGPOiuqdOz"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg5VrIlGq8DN"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.version.VERSION)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M94RjPXSq8Ls"
      },
      "source": [
        "!git clone --depth 1 -b v2.3.0 https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0lVwnoIq8R1"
      },
      "source": [
        "!pip install -Uqr models/official/requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQm0diSOsQpF"
      },
      "source": [
        "**Note** \n",
        "After installing the required Python packages, restart the Colab Runtime Engine (Menu > Runtime > Restart runtime...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye--SBuurgt-"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import sys\n",
        "sys.path.append('models')\n",
        "from official.nlp.data import classifier_data_lib\n",
        "from official.nlp.bert import tokenization\n",
        "from official.nlp import optimization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc20C2Z4rxms"
      },
      "source": [
        "print(\"TF Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxQwmHLlsBag"
      },
      "source": [
        "Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L54a3ygPr1iK"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('https://archive.org/download/fine-tune-bert-tensorflow-train.csv/train.csv.zip',\n",
        "                 compression='zip', low_memory=False)\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXWElUkIsddR"
      },
      "source": [
        "df.tail(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ny920uutG0Q"
      },
      "source": [
        "df.target.plot(kind='hist', title='Target distribution');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc3CkBcttQie"
      },
      "source": [
        "Create tf.data.Datasets for Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs1DgwcatMl6"
      },
      "source": [
        "train_df, remaining = train_test_split(df, random_state=42, train_size=0.0075, stratify=df.target.values)\n",
        "valid_df, _ = train_test_split(remaining, random_state=42, train_size=0.00075, stratify=remaining.target.values)\n",
        "train_df.shape, valid_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFZpYQ-7tkzd"
      },
      "source": [
        "with tf.device('/cpu:0'):\n",
        "  train_data = tf.data.Dataset.from_tensor_slices((train_df.question_text.values, train_df.target.values))\n",
        "  valid_data = tf.data.Dataset.from_tensor_slices((valid_df.question_text.values, valid_df.target.values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5zXO8SovRW7"
      },
      "source": [
        "for text, label in train_data.take(5):\n",
        "    print(text, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-ChcWfWvZRk"
      },
      "source": [
        "for text, label in valid_data.take(5):\n",
        "    print(text, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8peFMBNvu6a"
      },
      "source": [
        "Download a Pre-trained BERT Model from TensorFlow Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoWkpOryvpi-"
      },
      "source": [
        "label_list = [0, 1] # We have 2 here. (toxic or not)\n",
        "max_seq_length = 128 # maximum length of (token) input sequences\n",
        "train_batch_size = 32\n",
        "\n",
        "# Details: https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\",\n",
        "                            trainable=True)\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5cNp8hywqAL"
      },
      "source": [
        "Test the tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MfIQ7PpwWto"
      },
      "source": [
        "tokenizer.wordpiece_tokenizer.tokenize('hi, What is the easiest and most simple thing I can do to improve my health?')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W_k4n_vwkBN"
      },
      "source": [
        "tokenizer.convert_tokens_to_ids(tokenizer.wordpiece_tokenizer.tokenize('hi, What is the easiest and most simple thing I can do to improve my health?'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD1P9nLsxIlF"
      },
      "source": [
        "Now we need to transform our data into a format BERT understands. This involves two steps. create InputExamples using classifier_data_lib's constructor InputExample provided in the BERT library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AziVl4A9w0nV"
      },
      "source": [
        "def to_feature(text, label, label_list=label_list, max_seq_length=max_seq_length, tokenizer=tokenizer):\n",
        "  example = classifier_data_lib.InputExample(guid = None,\n",
        "                                            text_a = text.numpy(), \n",
        "                                            text_b = None, \n",
        "                                            label = label.numpy())\n",
        "  feature = classifier_data_lib.convert_single_example(0, example, label_list,\n",
        "                                    max_seq_length, tokenizer)\n",
        "  \n",
        "  return (feature.input_ids, feature.input_mask, feature.segment_ids, feature.label_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrUOc05GxgHr"
      },
      "source": [
        "You want to use Dataset.map to apply this function to each element of the dataset. Dataset.map runs in graph mode.\n",
        "\n",
        "Graph tensors do not have a value.\n",
        "In graph mode you can only use TensorFlow Ops and functions.\n",
        "So you can't .map this function directly: You need to wrap it in a tf.py_function. The tf.py_function will pass regular tensors (with a value and a .numpy() method to access it), to the wrapped python function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDQEPHR7xY_Q"
      },
      "source": [
        "def to_feature_map(text, label):\n",
        "  input_ids, input_mask, segment_ids, label_id = tf.py_function(to_feature, inp=[text, label], \n",
        "                                Tout=[tf.int32, tf.int32, tf.int32, tf.int32])\n",
        "\n",
        "  input_ids.set_shape([max_seq_length])\n",
        "  input_mask.set_shape([max_seq_length])\n",
        "  segment_ids.set_shape([max_seq_length])\n",
        "  label_id.set_shape([])\n",
        "\n",
        "  x = {\n",
        "        'input_word_ids': input_ids,\n",
        "        'input_mask': input_mask,\n",
        "        'input_type_ids': segment_ids\n",
        "    }\n",
        "  return (x, label_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Q23LdFlxxaU"
      },
      "source": [
        "Create a TensorFlow Input Pipeline with tf.data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_Ix5cB7xqjg"
      },
      "source": [
        "with tf.device('/cpu:0'):\n",
        "  # train\n",
        "  train_data = (train_data.map(to_feature_map,\n",
        "                              num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "                          #.cache()\n",
        "                          .shuffle(1000)\n",
        "                          .batch(32, drop_remainder=True)\n",
        "                          .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "  # valid\n",
        "  valid_data = (valid_data.map(to_feature_map,\n",
        "                            num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "                          .batch(32, drop_remainder=True)\n",
        "                          .prefetch(tf.data.experimental.AUTOTUNE)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciNXmRu5yKBg"
      },
      "source": [
        "*The* resulting `tf.data.Datasets` return `(features, labels)` pairs, as expected by [`keras.Model.fit`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWgOUo-kyEqg"
      },
      "source": [
        "train_data.element_spec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-SrkrvsySMb"
      },
      "source": [
        "valid_data.element_spec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqcti_yLytL5"
      },
      "source": [
        "Classification Head to the BERT Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hITDp0gIygAV"
      },
      "source": [
        "def create_model():\n",
        "  input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                      name=\"input_word_ids\")\n",
        "  input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                  name=\"input_mask\")\n",
        "  input_type_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                  name=\"input_type_ids\")\n",
        "\n",
        "  pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, input_type_ids])\n",
        "\n",
        "  drop = tf.keras.layers.Dropout(0.4)(pooled_output)\n",
        "  output = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"output\")(drop)\n",
        "\n",
        "  model = tf.keras.Model(\n",
        "    inputs={\n",
        "        'input_word_ids': input_word_ids,\n",
        "        'input_mask': input_mask,\n",
        "        'input_type_ids': input_type_ids\n",
        "    },\n",
        "    outputs=output)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi89_Rh2zvPx"
      },
      "source": [
        "Fine Tune BERT for text classifications."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtmeSGxmzLZZ"
      },
      "source": [
        "model = create_model()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNpTPNItz36R"
      },
      "source": [
        "tf.keras.utils.plot_model(model=model, show_shapes=True, dpi=76, )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twrkENT00BOh"
      },
      "source": [
        "# Train model\n",
        "epochs = 4\n",
        "history = model.fit(train_data,\n",
        "                    validation_data=valid_data,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiwG6Cb314V-"
      },
      "source": [
        "Evaluate the BERT Text Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Aar6ucd13pc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, metric):\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.plot(history.history['val_'+metric], '')\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([metric, 'val_'+metric])\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5cnlKO82Hwi"
      },
      "source": [
        "plot_graphs(history, 'loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omYYYZP92JgU"
      },
      "source": [
        "model.evaluate(valid_data, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxLSj1tc7lvi"
      },
      "source": [
        "sample_example = [\"That movie is pretty badly scripted !\"]\n",
        "test_data = tf.data.Dataset.from_tensor_slices((sample_example, [0]*len(sample_example)))\n",
        "test_data = (test_data.map(to_feature_map).batch(1))\n",
        "preds = model.predict(test_data)\n",
        "#['Toxic' if pred >=0.5 else 'Sincere' for pred in preds]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnpaL4lN9sBT"
      },
      "source": [
        "preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-XzXr2T7q_-"
      },
      "source": [
        "if preds >= 0.5:\n",
        "  print(\"Toxic text\")\n",
        "else:\n",
        "  print(\"Sincere text\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}